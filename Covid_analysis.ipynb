{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, trim, when, lit, year, month, dayofmonth, to_date, count, coalesce, floor, avg, regexp_replace, countDistinct, concat\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pandas as pd\n",
    "\n",
    "# Инициализация SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MetadataCleaningAndOptimization\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"LEGACY\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "input_hdfs_csv_path = \"hdfs:///covid_dataset/metadata/metadata_raw.csv\" # Путь к исходному CSV-файлу с метаданными в HDFS \n",
    "output_optimized_parquet_table_name = \"covid_metadata_optimized_table\" # Путь в HDFS, куда будут сохранены оптимизированные данные в формате Parquet\n",
    "output_optimized_parquet_path = \"hdfs:///covid_dataset/metadata_optimized/\"\n",
    "output_hdfs_csv_path = \"hdfs:///covid_dataset/metadata/metadata_cleaned.csv\" # Путь в HDFS, куда будут сохранены очищенные данные в формате CSV (для удобства просмотра)\n",
    "\n",
    "# Загрузка исходных данных \n",
    "df = spark.read.csv(input_hdfs_csv_path, header=True, inferSchema=True)\n",
    "\n",
    "# Удаление ненужных колонок, у нас это: '_c29' \n",
    "if '_c29' in df.columns:\n",
    "    df = df.drop('_c29')\n",
    "\n",
    "# Удаление полностью идентичных строк из DataFrame\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# Очистка и стандартизация колонки 'finding' (диагноз) значением \"unknown\"\n",
    "df = df.withColumn(\"finding\",\n",
    "                    when(col(\"finding\").isNull() | (trim(col(\"finding\")) == \"\"), lit(\"unknown\"))\n",
    "                    .otherwise(col(\"finding\")))\n",
    "\n",
    "# Приведение всех значений в колонке 'finding' к нижнему регистру и удаление пробелов по краям\n",
    "df = df.withColumn(\"finding\", lower(trim(col(\"finding\"))))\n",
    "\n",
    "# Создание новой колонки 'finding_unified' для стандартизации диагнозов\n",
    "# Это позволяет сгруппировать похожие диагнозы в общие категории. У нас это: \"covid-19\", \"other pneumonia\", \"tuberculosis\", \"no finding\", \"other finding\"\n",
    "df = df.withColumn(\"finding_unified\",\n",
    "    when(col(\"finding\").contains(\"covid\"), \"covid-19\") # Если содержит \"covid\", то \"covid-19\"\n",
    "    .when(col(\"finding\").contains(\"pneumonia\") & (~col(\"finding\").contains(\"covid\")), \"other pneumonia\") # Если пневмония, но не ковид, то \"other pneumonia\"\n",
    "    .when(col(\"finding\").contains(\"tuberculosis\"), \"tuberculosis\") # Если туберкулез, то \"tuberculosis\"\n",
    "    .when(col(\"finding\").contains(\"no finding\"), \"no finding\") # Если \"no finding\", то \"no finding\"\n",
    "    .otherwise(\"other finding\") # Все остальное - \"other finding\"\n",
    ")\n",
    "\n",
    "# Стандартизация колонки 'RT_PCR_positive' (результат ПЦР-теста) \n",
    "# Приведение значений 'Y'/'y' к 'Y', 'N'/'n' к 'N', остальные - 'UNKNOWN'\n",
    "if \"RT_PCR_positive\" in df.columns:\n",
    "    df = df.withColumn(\"RT_PCR_positive\",\n",
    "        when(lower(col(\"RT_PCR_positive\")) == \"y\", \"Y\")\n",
    "        .when(lower(col(\"RT_PCR_positive\")) == \"n\", \"N\")\n",
    "        .otherwise(\"UNKNOWN\")\n",
    "    )\n",
    "\n",
    "# Стандартизация колонки 'survival' (выживаемость) \n",
    "# Приведение значений 'Y'/'y' к 'Y', 'N'/'n' к 'N', остальные - 'UNKNOWN'\n",
    "if \"survival\" in df.columns:\n",
    "    df = df.withColumn(\"survival\",\n",
    "        when(lower(col(\"survival\")) == \"y\", \"Y\")\n",
    "        .when(lower(col(\"survival\")) == \"n\", \"N\")\n",
    "        .otherwise(\"UNKNOWN\")\n",
    "    )\n",
    "\n",
    "# Парсинг и извлечение даты \n",
    "# Создание новой колонки 'date_parsed' путем попытки парсинга колонки 'date' с использованием нескольких форматов\n",
    "df = df.withColumn(\"date_parsed\",\n",
    "    coalesce(\n",
    "        to_date(col(\"date\"), \"MMMM d, yyyy\"), # Например, \"July 5, 2025\"\n",
    "        to_date(col(\"date\"), \"MMMM dd, yyyy\"),# Например, \"July 05, 2025\"\n",
    "        to_date(col(\"date\"), \"MMM d, yyyy\"),  # Например, \"Jul 5, 2025\"\n",
    "        to_date(col(\"date\"), \"MMM dd, yyyy\"), # Например, \"Jul 05, 2025\"\n",
    "        to_date(col(\"date\"), \"yyyy-MM-dd\"),   # Стандартный формат \"2025-07-05\"\n",
    "        to_date(col(\"date\"), \"MM/dd/yyyy\"),   # \"07/05/2025\"\n",
    "        to_date(col(\"date\"), \"M/d/yy\"),       # \"7/5/25\"\n",
    "        to_date(col(\"date\"), \"yyyy\")          # Только год \"2025\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Извлечение года, месяца и дня из спарсенной даты\n",
    "df = df.withColumn(\"year\", year(col(\"date_parsed\"))) \\\n",
    "       .withColumn(\"month\", month(col(\"date_parsed\"))) \\\n",
    "       .withColumn(\"day\", dayofmonth(col(\"date_parsed\")))\n",
    "\n",
    "# Создание колонки 'is_covid': 1, если 'finding_unified' - \"covid-19\", иначе 0\n",
    "df = df.withColumn(\"is_covid\", when(col(\"finding_unified\") == \"covid-19\", 1).otherwise(0))\n",
    "\n",
    "# Обработка колонки 'age' \n",
    "if \"age\" in df.columns:\n",
    "    # Попытка привести 'age' к целочисленному типу. Если не удается, устанавливается None\n",
    "    df = df.withColumn(\"age_numeric\",\n",
    "                        when(col(\"age\").cast(IntegerType()).isNotNull(), col(\"age\").cast(IntegerType()))\n",
    "                        .otherwise(None))\n",
    "\n",
    "    # Вычисление медианы возраста для заполнения пропущенных значений\n",
    "    filtered_df_for_median = df.filter(col(\"age_numeric\").isNotNull())\n",
    "    if filtered_df_for_median.count() > 0:\n",
    "        median_age = filtered_df_for_median.approxQuantile(\"age_numeric\", [0.5], 0.25)[0]\n",
    "        # Заполнение пропущенных значений в 'age_numeric' вычисленной медианой\n",
    "        df = df.withColumn(\"age_numeric\", coalesce(col(\"age_numeric\"), lit(int(median_age))))\n",
    "    else:\n",
    "        # Если все значения 'age_numeric' NULL, заполняем 0 \n",
    "        df = df.withColumn(\"age_numeric\", coalesce(col(\"age_numeric\"), lit(0)))\n",
    "\n",
    "    # Создание колонки 'age_group' на основе 'age_numeric'\n",
    "    df = df.withColumn(\"age_group\",\n",
    "                        when(col(\"age_numeric\") < 18, \"child\")\n",
    "                        .when((col(\"age_numeric\") >= 18) & (col(\"age_numeric\") < 65), \"adult\")\n",
    "                        .when(col(\"age_numeric\") >= 65, \"senior\")\n",
    "                        .otherwise(\"unknown\"))\n",
    "\n",
    "# Обработка колонки 'sex' \n",
    "if \"sex\" in df.columns:\n",
    "    # Вычисление mode (наиболее часто встречающегося значения) для заполнения пропущенных\n",
    "    mode_sex_row = df.filter(col(\"sex\").isNotNull()).groupBy(\"sex\").count().orderBy(col(\"count\").desc()).first()\n",
    "    if mode_sex_row:\n",
    "        mode_sex = mode_sex_row[\"sex\"]\n",
    "        # Заполнение пропущенных значений в 'sex' вычисленной mode\n",
    "        df = df.withColumn(\"sex\", coalesce(col(\"sex\"), lit(mode_sex)))\n",
    "    else:\n",
    "        # Если все значения 'sex' NULL, заполняем \"UNKNOWN\"\n",
    "        df = df.withColumn(\"sex\", coalesce(col(\"sex\"), lit(\"UNKNOWN\")))\n",
    "\n",
    "# Обработка колонки 'temperature' \n",
    "if \"temperature\" in df.columns:\n",
    "    # Очистка нереалистичных значений температуры (ниже 35 или выше 42 градусов Цельсия)\n",
    "    df = df.withColumn(\"temperature\",\n",
    "                        when((col(\"temperature\").isNotNull()) & ((col(\"temperature\") < 35) | (col(\"temperature\") > 42)), None)\n",
    "                        .otherwise(col(\"temperature\")))\n",
    "    # Вычисление среднего значения температуры для заполнения пропущенных\n",
    "    avg_temp_row = df.filter(col(\"temperature\").isNotNull()).agg(avg(\"temperature\")).collect()[0][0]\n",
    "    if avg_temp_row is not None:\n",
    "        avg_temp = avg_temp_row\n",
    "        # Заполнение пропущенных значений в 'temperature' вычисленным средним\n",
    "        df = df.withColumn(\"temperature\", coalesce(col(\"temperature\"), lit(avg_temp)))\n",
    "\n",
    "# Обработка колонки 'pO2_saturation' (насыщение кислородом) \n",
    "if \"pO2_saturation\" in df.columns:\n",
    "    # Очистка нереалистичных значений сатурации (ниже 70 или выше 100) \n",
    "    df = df.withColumn(\"pO2_saturation\",\n",
    "                        when((col(\"pO2_saturation\").isNotNull()) & ((col(\"pO2_saturation\") < 70) | (col(\"pO2_saturation\") > 100)), None)\n",
    "                        .otherwise(col(\"pO2_saturation\")))\n",
    "    # Вычисление среднего значения сатурации для заполнения пропущенных\n",
    "    avg_po2_row = df.filter(col(\"pO2_saturation\").isNotNull()).agg(avg(\"pO2_saturation\")).collect()[0][0]\n",
    "    if avg_po2_row is not None:\n",
    "        avg_po2 = avg_po2_row\n",
    "        # Заполнение пропущенных значений в 'pO2_saturation' вычисленным средним\n",
    "        df = df.withColumn(\"pO2_saturation\", coalesce(col(\"pO2_saturation\"), lit(avg_po2)))\n",
    "\n",
    "# Создание полного пути к изображению в HDFS \n",
    "# Создание колонки 'hdfs_image_path' путем конкатенации базового пути HDFS и имени файла изображения. Чтобы Spark знал где искать\n",
    "df_cleaned_final = df.withColumn(\"hdfs_image_path\", concat(lit(\"hdfs:///covid_dataset/images/\"), col(\"filename\")))\n",
    "\n",
    "# Фильтрация строк с некорректными путями к изображениям \n",
    "df_cleaned_final = df_cleaned_final.filter(col(\"hdfs_image_path\").isNotNull() & (trim(col(\"hdfs_image_path\")) != \"\"))\n",
    "\n",
    "# Вывод статистики по очищенному DataFrame \n",
    "total_rows = df_cleaned_final.count()\n",
    "print(f\"Финальное количество строк: {total_rows}\")\n",
    "\n",
    "print(\"Схема DataFrame\")\n",
    "df_cleaned_final.printSchema()\n",
    "\n",
    "# Распределение пропущенных значений по колонкам \n",
    "print(\"Распределение пропущенных значений (процент)\")\n",
    "missing_data = []\n",
    "for column in df_cleaned_final.columns:\n",
    "    missing_count = df_cleaned_final.filter(col(column).isNull() | (trim(col(column)) == \"\")).count()\n",
    "    missing_percentage = (missing_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "    missing_data.append({\"Column\": column, \"Missing Count\": missing_count, \"Missing Percentage\": f\"{missing_percentage:.2f}%\"})\n",
    "\n",
    "# Вывод результатов в виде Pandas DataFrame\n",
    "print(pd.DataFrame(missing_data).set_index(\"Column\"))\n",
    "\n",
    "# Общая статистика для числовых колонок \n",
    "print(\"Общая статистика для числовых колонок\")\n",
    "numeric_cols = [c for c, t in df_cleaned_final.dtypes if t in [\"int\", \"double\", \"long\", \"float\"] and c not in [\"year\", \"month\", \"day\", \"is_covid\"]]\n",
    "if numeric_cols:\n",
    "    # summary(): Вычисляет статистические сводки (count, mean, stddev, min, max) для выбранных колонок\n",
    "    df_cleaned_final.select(numeric_cols).summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\").show()\n",
    "else:\n",
    "    print(\"Числовых колонок для статистики не найдено.\")\n",
    "\n",
    "# Распределение уникальных значений для категориальных колонок \n",
    "print(\"Распределение уникальных значений для некоторых категориальных колонок\")\n",
    "categorical_cols_to_check = [\"finding_unified\", \"sex\", \"view\", \"modality\", \"location\", \"age_group\", \"RT_PCR_positive\", \"survival\"]\n",
    "for column in categorical_cols_to_check:\n",
    "    if column in df_cleaned_final.columns:\n",
    "        print(f\"\\nКолонка '{column}':\")\n",
    "        # Подсчет количества уникальных значений\n",
    "        num_distinct = df_cleaned_final.select(countDistinct(column)).collect()[0][0]\n",
    "        if num_distinct < 50:\n",
    "            df_cleaned_final.groupBy(column).count().orderBy(col(\"count\").desc()).show(truncate=False)\n",
    "        else:\n",
    "            # Если уникальных значений много, показываем только топ-20\n",
    "            df_cleaned_final.groupBy(column).count().orderBy(col(\"count\").desc()).limit(20).show(truncate=False)\n",
    "    else:\n",
    "        print(f\"Колонка '{column}' не найдена.\")\n",
    "\n",
    "# Сохранение очищенных данных в HDFS \n",
    "# Сохранение DataFrame в формате Parquet\n",
    "# Перезаписывает данные, если они уже существуют по указанному пути\n",
    "# Разбивает данные на директории по году и месяцу (например, /year=2020/month=01)\n",
    "# Дополнительно организует данные внутри партиций в \"бакеты\"\n",
    "# Сохраняет DataFrame как управляемую таблицу в Hive Metastore\n",
    "print(f\"\\nСохраняем очищенные данные в HDFS в формате Parquet с партиционированием и бакетированием по пути: {output_optimized_parquet_path}\")\n",
    "df_cleaned_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .bucketBy(10, \"finding_unified\", \"sex\") \\\n",
    "    .saveAsTable(output_optimized_parquet_table_name, path=output_optimized_parquet_path, format=\"parquet\")\n",
    "print(f\"Данные успешно сохранены в Parquet в виде таблицы '{output_optimized_parquet_table_name}'.\")\n",
    "\n",
    "# Сохранение DataFrame в формате CSV\n",
    "print(f\"\\nСохраняем очищенные данные в HDFS в формате CSV: {output_hdfs_csv_path}\")\n",
    "df_cleaned_final.write.mode(\"overwrite\").csv(output_hdfs_csv_path, header=True)\n",
    "print(\"Данные успешно сохранены в CSV.\")\n",
    "\n",
    "# Остановка SparkSession\n",
    "spark.stop()\n",
    "print(\"SparkSession остановлена. Очистка и сохранение метаданных завершены.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальное количество строк: 950\n",
    "Схема DataFrame\n",
    "root\n",
    " |-- patientid: string (nullable = true)\n",
    " |-- offset: integer (nullable = true)\n",
    " |-- sex: string (nullable = false)\n",
    " |-- age: integer (nullable = true)\n",
    " |-- finding: string (nullable = true)\n",
    " |-- RT_PCR_positive: string (nullable = false)\n",
    " |-- survival: string (nullable = false)\n",
    " |-- intubated: string (nullable = true)\n",
    " |-- intubation_present: string (nullable = true)\n",
    " |-- went_icu: string (nullable = true)\n",
    " |-- in_icu: string (nullable = true)\n",
    " |-- needed_supplemental_O2: string (nullable = true)\n",
    " |-- extubated: string (nullable = true)\n",
    " |-- temperature: double (nullable = false)\n",
    " |-- pO2_saturation: double (nullable = false)\n",
    " |-- leukocyte_count: double (nullable = true)\n",
    " |-- neutrophil_count: double (nullable = true)\n",
    " |-- lymphocyte_count: double (nullable = true)\n",
    " |-- view: string (nullable = true)\n",
    " |-- modality: string (nullable = true)\n",
    " |-- date: string (nullable = true)\n",
    " |-- location: string (nullable = true)\n",
    " |-- folder: string (nullable = true)\n",
    " |-- filename: string (nullable = true)\n",
    " |-- doi: string (nullable = true)\n",
    " |-- url: string (nullable = true)\n",
    " |-- license: string (nullable = true)\n",
    " |-- clinical_notes: string (nullable = true)\n",
    " |-- other_notes: string (nullable = true)\n",
    " |-- finding_unified: string (nullable = false)\n",
    " |-- date_parsed: date (nullable = true)\n",
    " |-- year: integer (nullable = true)\n",
    " |-- month: integer (nullable = true)\n",
    " |-- day: integer (nullable = true)\n",
    " |-- is_covid: integer (nullable = false)\n",
    " |-- age_numeric: integer (nullable = false)\n",
    " |-- age_group: string (nullable = false)\n",
    " |-- hdfs_image_path: string (nullable = true)\n",
    "\n",
    "Распределение пропущенных значений (процент)\n",
    "                        Missing Count Missing Percentage\n",
    "Column                                                  \n",
    "patientid                           0              0.00%\n",
    "offset                            253             26.63%\n",
    "sex                                 0              0.00%\n",
    "age                               237             24.95%\n",
    "finding                             0              0.00%\n",
    "RT_PCR_positive                     0              0.00%\n",
    "survival                            0              0.00%\n",
    "intubated                         702             73.89%\n",
    "intubation_present                700             73.68%\n",
    "went_icu                          553             58.21%\n",
    "in_icu                            615             64.74%\n",
    "needed_supplemental_O2            860             90.53%\n",
    "extubated                         913             96.11%\n",
    "temperature                         0              0.00%\n",
    "pO2_saturation                      0              0.00%\n",
    "leukocyte_count                   934             98.32%\n",
    "neutrophil_count                  922             97.05%\n",
    "lymphocyte_count                  910             95.79%\n",
    "view                                0              0.00%\n",
    "modality                            0              0.00%\n",
    "date                              289             30.42%\n",
    "location                           56              5.89%\n",
    "folder                              0              0.00%\n",
    "filename                            0              0.00%\n",
    "doi                               568             59.79%\n",
    "url                                 0              0.00%\n",
    "license                           246             25.89%\n",
    "clinical_notes                    182             19.16%\n",
    "other_notes                       510             53.68%\n",
    "finding_unified                     0              0.00%\n",
    "date_parsed                       299             31.47%\n",
    "year                              299             31.47%\n",
    "month                             299             31.47%\n",
    "day                               299             31.47%\n",
    "is_covid                            0              0.00%\n",
    "age_numeric                         0              0.00%\n",
    "age_group                           0              0.00%\n",
    "hdfs_image_path                     0              0.00%\n",
    "Общая статистика для числовых колонок\n",
    "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
    "|summary|           offset|               age|       temperature|    pO2_saturation|   leukocyte_count|  neutrophil_count|  lymphocyte_count|       age_numeric|\n",
    "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
    "|  count|              697|               713|               950|               950|                16|                28|                40|               950|\n",
    "|   mean|9.083213773314204|  53.5343618513324| 38.17012987013001| 88.99027777777643| 5.024374999999999| 5.307142857142857| 4.638049999999999|  50.1578947368421|\n",
    "| stddev|31.66407673016952|16.949006804228343|0.2501870716339055|2.2348620121439198|2.6603407519839757|3.4899558069396144|20.550032835397065|15.806999682966937|\n",
    "|    min|             -360|                18|              36.0|              70.0|              0.22|               0.0|               0.4|                18|\n",
    "|    max|              365|                94|              40.0|             100.0|              11.2|              12.9|             131.0|                94|\n",
    "+-------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
    "\n",
    "Распределение уникальных значений для некоторых категориальных колонок\n",
    "\n",
    "Колонка 'finding_unified':\n",
    "+---------------+-----+\n",
    "|finding_unified|count|\n",
    "+---------------+-----+\n",
    "|covid-19       |584  |\n",
    "|other pneumonia|242  |\n",
    "|other finding  |84   |\n",
    "|no finding     |22   |\n",
    "|tuberculosis   |18   |\n",
    "+---------------+-----+\n",
    "\n",
    "\n",
    "Колонка 'sex':\n",
    "+---+-----+\n",
    "|sex|count|\n",
    "+---+-----+\n",
    "|M  |639  |\n",
    "|F  |311  |\n",
    "+---+-----+\n",
    "\n",
    "\n",
    "Колонка 'view':\n",
    "+---------+-----+\n",
    "|view     |count|\n",
    "+---------+-----+\n",
    "|PA       |344  |\n",
    "|AP Supine|234  |\n",
    "|AP       |203  |\n",
    "|L        |84   |\n",
    "|Axial    |68   |\n",
    "|Coronal  |16   |\n",
    "|AP Erect |1    |\n",
    "+---------+-----+\n",
    "\n",
    "\n",
    "Колонка 'modality':\n",
    "+--------+-----+\n",
    "|modality|count|\n",
    "+--------+-----+\n",
    "|X-ray   |866  |\n",
    "|CT      |84   |\n",
    "+--------+-----+\n",
    "\n",
    "\n",
    "Колонка 'location':\n",
    "+------------------------------------------------------------------------------+-----+\n",
    "|location                                                                      |count|\n",
    "+------------------------------------------------------------------------------+-----+\n",
    "|Hannover Medical School, Hannover, Germany                                    |164  |\n",
    "|Italy                                                                         |81   |\n",
    "|Melbourne, Australia                                                          |57   |\n",
    "|NULL                                                                          |56   |\n",
    "|United Kingdom                                                                |25   |\n",
    "|Spain                                                                         |24   |\n",
    "|Milan, Italy                                                                  |22   |\n",
    "|Humanitas Clinical and Research Hospital, Rozzano, Milan, Italy               |20   |\n",
    "|Valencia, Spain                                                               |15   |\n",
    "|Edinburgh, United Kingdom                                                     |15   |\n",
    "|Hong Kong                                                                     |14   |\n",
    "|South Korea                                                                   |13   |\n",
    "|The First Affiliated Hospital of Anhui Medical University, Hefei, Anhui, China|11   |\n",
    "|Alexandria, Egypt                                                             |11   |\n",
    "|Mount Sinai Hospital, Toronto, Ontario, Canada                                |11   |\n",
    "|Australia                                                                     |11   |\n",
    "|Wenzhou, China                                                                |10   |\n",
    "|Brescia, Italy                                                                |10   |\n",
    "|Tehran, Iran                                                                  |9    |\n",
    "|Nottingham, United Kingdom                                                    |9    |\n",
    "+------------------------------------------------------------------------------+-----+\n",
    "\n",
    "\n",
    "Колонка 'age_group':\n",
    "+---------+-----+\n",
    "|age_group|count|\n",
    "+---------+-----+\n",
    "|adult    |731  |\n",
    "|senior   |219  |\n",
    "+---------+-----+\n",
    "\n",
    "\n",
    "Колонка 'RT_PCR_positive':\n",
    "+---------------+-----+\n",
    "|RT_PCR_positive|count|\n",
    "+---------------+-----+\n",
    "|UNKNOWN        |579  |\n",
    "|Y              |371  |\n",
    "+---------------+-----+\n",
    "\n",
    "\n",
    "Колонка 'survival':\n",
    "+--------+-----+\n",
    "|survival|count|\n",
    "+--------+-----+\n",
    "|UNKNOWN |589  |\n",
    "|Y       |285  |\n",
    "|N       |76   |\n",
    "+--------+-----+\n",
    "\n",
    "\n",
    "Сохраняем очищенные данные в HDFS в формате Parquet с партиционированием и бакетированием по пути: hdfs:///covid_dataset/metadata_optimized/\n",
    "                                                                                \n",
    "Данные успешно сохранены в Parquet в виде таблицы 'covid_metadata_optimized_table'.\n",
    "\n",
    "Сохраняем очищенные данные в HDFS в формате CSV: hdfs:///covid_dataset/metadata/metadata_cleaned.csv\n",
    "                                                                                \n",
    "Данные успешно сохранены в CSV.\n",
    "SparkSession остановлена. Очистка и сохранение метаданных завершены."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
